---
title: "Dynamic Forward and Backward Sparse Training\r (DFBST): Accelerated Deep Learning
  through\r Completely Sparse Training Schedule"
crossref: acml22
abstract: "Neural network sparsification has received a lot of\r attention in recent
  years. A number of dynamic\r sparse training methods have been developed that\r
  achieve significant sparsity levels during training,\r ensuring comparable performance
  to their dense\r counterparts. However, most of these methods update\r all the model
  parameters using dense gradients. To\r this end, gradient sparsification is achieved
  either\r by non-dynamic (fixed) schedule or computationally\r expensive dynamic
  pruning schedule. To alleviate\r these drawbacks, we propose Dynamic Forward and\r
  Backward Sparse Training (DFBST), an algorithm which\r dynamically sparsifies both
  the forward and backward\r passes using trainable masks, leading to a\r completely
  sparse training schedule. In contrast to\r existing sparse training methods, we
  propose\r separate learning for forward as well as backward\r masks. Our approach
  achieves state of the art\r performance in terms of both accuracy and sparsity\r
  compared to existing dynamic pruning algorithms on\r benchmark datasets, namely
  MNIST, CIFAR-10 and\r CIFAR-100."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pote23a
month: 0
tex_title: "Dynamic Forward and Backward Sparse Training\r (DFBST): Accelerated Deep
  Learning through\r Completely Sparse Training Schedule"
firstpage: 848
lastpage: 863
page: 848-863
order: 848
cycles: false
bibtex_author: Pote, Tejas and Ganaie, Muhammad Athar and Hassan, Atif and Khare,
  Swanand
author:
- given: Tejas
  family: Pote
- given: Muhammad Athar
  family: Ganaie
- given: Atif
  family: Hassan
- given: Swanand
  family: Khare
date: 2023-04-13
address:
container-title: "Proceedings of The 14th Asian Conference on Machine\r Learning"
volume: '189'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 4
  - 13
pdf: https://proceedings.mlr.press/v189/pote23a/pote23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
